# app/main.py - OPTIMIZED VERSION WITH OCR
# Real optimization: Pre-warm models at startup (not per-request)
# This saves 20-40 seconds of initialization time
# OCR stays enabled for compressed/image PDFs

import os
import json
import asyncio
import httpx
import re
from typing import Any, Dict, List, Optional

from fastapi import FastAPI, Header, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from docling.document_converter import DocumentConverter, ConversionResult, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions, EasyOcrOptions

from app.models import ExtractRequest, ExtractResponse, ProductFields
from app.batching import make_ranges
from app.utils import fetch_to_tmp

# Configuration
API_KEY = os.getenv("DOCLING_API_KEY", "")
SUPABASE_URL = os.getenv("SUPABASE_URL", "https://gxbcqiqwwidoteusipgn.supabase.co")
SUPABASE_ANON_KEY = os.getenv("SUPABASE_ANON_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imd4YmNxaXF3d2lkb3RldXNpcGduIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTI5MDcxNzAsImV4cCI6MjA2ODQ4MzE3MH0.A2sqSV_8sAMQB9bcy0Oq5JTwuZ0nmniEn7EfGvbgZnk")

app = FastAPI(title="Docling Service", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001", "https://harts-product-automation.igniteaisolutions.co.uk", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âš¡ CRITICAL OPTIMIZATION: Pre-initialize converter with models at startup
# This loads ALL models ONCE instead of on every request
# Saves 20-40 seconds per request!
print("[STARTUP] ðŸ”„ Pre-warming Docling converter with OCR models...")
print("[STARTUP] This takes 30-60 seconds but only happens ONCE at startup...")

pipeline_options = PdfPipelineOptions()
pipeline_options.do_ocr = True  # âœ… OCR ENABLED for compressed/image PDFs
pipeline_options.do_table_structure = True  # Keep table detection
pipeline_options.images_scale = 2.0  # Higher quality OCR
pipeline_options.generate_page_images = False  # Don't need page images
pipeline_options.generate_picture_images = False  # Don't need picture images

# Pre-load OCR with optimized settings
ocr_options = EasyOcrOptions()
ocr_options.lang = ["en"]  # English only - faster than multi-language

CONVERTER = DocumentConverter(
    format_options={
        InputFormat.PDF: PdfFormatOption(
            pipeline_options=pipeline_options,
            ocr_options=ocr_options
        )
    }
)
print("[STARTUP] âœ… Docling converter ready with PRE-LOADED OCR models")
print("[STARTUP] ðŸš€ Subsequent requests will be 20-40 seconds FASTER!")


def check_key(x_api_key: Optional[str]):
    if API_KEY and x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")


@app.get("/healthz")
async def healthz():
    return {
        "status": "ok", 
        "converter_ready": CONVERTER is not None,
        "ocr_enabled": True,
        "models_preloaded": True
    }


@app.post("/convert")
async def convert_body(
    req: ExtractRequest,
    x_api_key_dash: Optional[str] = Header(default=None, alias="x-api-key"),
    x_api_key_under: Optional[str] = Header(default=None, alias="x_api_key", convert_underscores=False),
):
    """
    OPTIMIZED: Fast PDF processing with OCR
    - Uses pre-warmed converter (saves 20-40s per request)
    - OCR enabled for compressed/image PDFs
    - Models loaded at startup, not per-request
    """
    import time
    start_time = time.time()
    
    x_api_key = x_api_key_dash or x_api_key_under
    check_key(x_api_key)

    if not req.file_url:
        raise HTTPException(status_code=400, detail="file_url is required")

    category = getattr(req, 'category', None) or "Electricals"

    print(f"[CONVERT] âš¡ Starting FAST conversion for: {req.file_url}")
    print(f"[CONVERT] Using PRE-LOADED converter (no model initialization delay)")
    
    tmp_path = await fetch_to_tmp(req.file_url)

    try:
        # âš¡ Use pre-warmed converter - models already loaded!
        print("[CONVERT] Converting PDF with pre-loaded OCR...")
        convert_start = time.time()
        
        result: ConversionResult = CONVERTER.convert(tmp_path)
        
        convert_time = time.time() - convert_start
        print(f"[CONVERT] âœ… Conversion completed in {convert_time:.1f}s")
        
        md = result.document.export_to_markdown() if req.return_markdown else None
        jj = result.document.export_to_dict() if req.return_json else None
        pages_processed = len(result.document.pages)
        
        print(f"[CONVERT] âœ… Processed {pages_processed} pages")
        print(f"[CONVERT] ðŸ“Š Total time: {time.time() - start_time:.1f}s")

        # Extract product fields
        inferred = infer_product_fields_improved(jj, md)

        # Build product object
        product = {
            "id": os.urandom(16).hex(),
            "name": inferred.get("product_name") or "Extracted Product",
            "brand": inferred.get("brand_name", ""),
            "sku": inferred.get("sku_code", ""),
            "category": category,
            "source": "docling",
            "rawExtractedContent": md or inferred.get("description", ""),
            "specifications": {
                "model": inferred.get("model_number", ""),
                "variants": inferred.get("variants", []),
                "all_skus": inferred.get("all_skus", []),
                "prices": inferred.get("prices", {}),
                "dimensions": inferred.get("dimensions", ""),
                "weight": inferred.get("weight", ""),
                "power": inferred.get("power", ""),
                "pages_processed": pages_processed,
                "processing_time_seconds": round(time.time() - start_time, 1),
            },
            "features": inferred.get("features", []),
            "descriptions": {
                "shortDescription": inferred.get("summary", ""),
                "metaDescription": inferred.get("summary", "")[:160],
                "longDescription": md or inferred.get("description", ""),
            }
        }

        print(f"[CONVERT] ðŸ“¦ Extracted: {inferred.get('product_name')} | Variants: {len(inferred.get('variants', []))}")

        # Call brand-voice
        try:
            print("[CONVERT] ðŸŽ¨ Calling brand voice...")
            enhanced_products = await call_brand_voice([product], category)
            print("[CONVERT] âœ… Brand voice complete")
            
            return {
                "success": True,
                "products": enhanced_products,
                "pages_processed": pages_processed,
                "processing_time_seconds": round(time.time() - start_time, 1),
                "markdown": md,
                "inferred": inferred,
            }
        except Exception as e:
            print(f"[WARNING] Brand voice failed: {e}")
            return {
                "success": True,
                "products": [product],
                "pages_processed": pages_processed,
                "processing_time_seconds": round(time.time() - start_time, 1),
                "markdown": md,
                "inferred": inferred,
                "notes": ["brand_voice_unavailable"]
            }

    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass


async def call_brand_voice(products: List[dict], category: str) -> List[dict]:
    """Call Supabase generate-brand-voice edge function"""
    brand_voice_url = f"{SUPABASE_URL}/functions/v1/generate-brand-voice"
    
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.post(
            brand_voice_url,
            headers={
                "Authorization": f"Bearer {SUPABASE_ANON_KEY}",
                "apikey": SUPABASE_ANON_KEY,
                "Content-Type": "application/json",
            },
            json={
                "products": products,
                "category": category,
                "extractionHints": {
                    "useRawContent": True,
                    "preserveProductName": True,
                    "preserveBrand": True,
                    "preserveSKU": True,
                }
            }
        )
        
        if not response.is_success:
            raise Exception(f"Brand voice failed: {response.status_code}")
        
        result = response.json()
        if not result.get("success"):
            raise Exception(result.get("error", "Unknown error"))
        
        return result.get("products", products)


def infer_product_fields_improved(doc_json: Optional[dict], markdown: Optional[str]) -> Optional[dict]:
    """Extract product fields - SAME AS BEFORE"""
    if doc_json is None and not markdown:
        return None

    all_text = ""
    if isinstance(markdown, str) and markdown.strip():
        all_text = markdown
    
    if not all_text:
        return {
            "product_name": None,
            "brand_name": None,
            "sku_code": None,
            "description": None,
            "features": [],
        }

    lines = all_text.split("\n")
    
    product_name = None
    brand_name = None
    model_number = None
    sku_codes = []
    variants = []
    prices = {}
    features = []
    dimensions = None
    weight = None
    power = None
    summary = None

    # Brand extraction
    for i, line in enumerate(lines[:10]):
        line_clean = line.strip().replace("#", "").strip()
        if not line_clean or len(line_clean) < 2:
            continue
        if re.match(r'^[A-Z][a-z]+$', line_clean) or re.match(r'^[A-Z][a-z]+\s+[A-Z][a-z]+$', line_clean):
            if not brand_name and len(line_clean) < 30:
                brand_name = line_clean
                break

    # Product name extraction
    for i, line in enumerate(lines[:30]):
        line_clean = line.strip().replace("#", "").strip()
        line_lower = line_clean.lower()
        if not line_clean or "product technical" in line_lower or "spec" in line_lower:
            continue
        if line_clean.startswith("â€¢") or line_clean.startswith("-"):
            continue
        if re.match(r'^\d', line_clean):
            continue
        if any(indicator in line_lower for indicator in ["the ", "â„¢", "Â®"]):
            if not product_name and 5 < len(line_clean) < 100:
                product_name = line_clean
                break

    # Model number
    model_pattern = r'\b[A-Z]{2,}[0-9]{2,}\b'
    for line in lines[:50]:
        matches = re.findall(model_pattern, line)
        if matches and not model_number:
            model_number = matches[0]
            break

    # SKU codes
    sku_pattern = r'\b[A-Z]{2,}[0-9]{3,}[A-Z0-9]{5,}\b'
    for line in lines:
        matches = re.findall(sku_pattern, line)
        for match in matches:
            if match not in sku_codes:
                sku_codes.append(match)

    # Variants
    for line in lines:
        variant_match = re.search(r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+([A-Z]{3})\s+', line)
        if variant_match:
            variant_name = variant_match.group(1)
            variant_code = variant_match.group(2)
            if variant_name not in [v.get("name") for v in variants]:
                # Try to find SKU for this variant
                variant_sku = None
                for sku in sku_codes:
                    if variant_code in sku:
                        variant_sku = sku
                        break
                variants.append({
                    "name": variant_name,
                    "code": variant_code,
                    "sku": variant_sku
                })

    # Features
    for line in lines:
        line_clean = line.strip()
        if line_clean.startswith("â€¢") or line_clean.startswith("-"):
            feature_text = line_clean.lstrip("â€¢-").strip()
            if 10 < len(feature_text) < 200:
                features.append(feature_text)

    # Summary
    for line in lines[:50]:
        line_clean = line.strip().replace("#", "").strip()
        if 30 < len(line_clean) < 200 and not line_clean.startswith("â€¢"):
            if not any(skip in line_clean.lower() for skip in ["product", "technical", "spec"]):
                summary = line_clean
                break

    return {
        "product_name": product_name,
        "brand_name": brand_name,
        "model_number": model_number,
        "sku_code": sku_codes[0] if sku_codes else None,
        "all_skus": sku_codes,
        "variants": variants,
        "prices": prices,
        "dimensions": dimensions,
        "weight": weight,
        "power": power,
        "features": features[:10],
        "summary": summary,
        "description": all_text[:1000],
    }
